<img  width=800 height=150 src="../../Images/Kafka/Kafka.png" ></img>

# **O que √© ?**

O Apache Kafka √© uma plataforma distribu√≠da de transmiss√£o de dados que √© capaz de publicar, subscrever, armazenar e processar fluxos de registro em tempo real.

Essa plataforma foi desenvolvida para processar fluxos de dados provenientes de diversas fontes e entreg√°-los a v√°rios clientes.

Em resumo, o Apache Kafka movimenta volumes imensos de dados n√£o apenas do ponto A ao ponto B, mas tamb√©m de A a Z e para qualquer outro local que voc√™ precisar simultaneamente.

- [Introduction to Kafka](https://www.youtube.com/watch?v=43d7YWY2w0Y)

- [Mais informa√ß√µes](https://www.redhat.com/pt-br/topics/integration/what-is-apache-kafka)

- [Documenta√ß√£o](https://kafka.apache.org/documentation/)

# **Para que serve ?**

Kafka abstrai os detalhes dos arquivos e fornece uma abstra√ß√£o mais limpa do log como um fluxo de mensagens. Isso permite um processamento de baixa lat√™ncia e suporte mais f√°cil para v√°rias fontes de dados e consumo de dados distribu√≠dos.

O Kafka permite usar os t√≥picos como tabelas, permitindo fazer queries para aquisi√ß√£o de dados, isso pode ser usado para uma arquitetura baseada em Eventos. Essa funcionalidade por√©m n√£o √© t√£o simples como √© descrito na documenta√ß√£o.

# **Como funciona ?**

O Kafka foi escrito nas linguagens de programa√ß√£o Java e Scala. Ele realiza as suas transmiss√µes de maneira ass√≠ncrona e pode ser considerado como um sistema distribu√≠do.

Em sua estrutura, o Kafka possui consumers e producers. Para definir esses termos, basta traduzir: os producers s√£o os produtores das mensagens (quem envia e distribui os dados); j√° os consumers s√£o os consumidores das mensagens (eles se inscrevem em um t√≥pico e ficam ouvindo as mensagem que chegar√£o).

![funcionalidades](../../Images/Kafka/Funcionamento.png)

# **Qual √© a Arquitetura ?**

![Arquitetura](../../Images/Kafka/Arquitetura.png)

A arquitetura do Apache Kafka √© organizada em torno de alguns termos chaves, s√£o eles: messages, topics, producers, consumers groups e os brokers. O Apache Kafka √© uma plataforma de stream (fluxo de dados) de alto throughput que desacopla os produtores de dados dos consumidores de dados

# **Como instalar ?**

- Voc√™ pode fazer download dos bin√°rios (ou at√© mesmo compilar o c√≥digo) a partir do site oficial da ferramenta. Neste mesmo site, voc√™ consegue encontrar um quickstart para rodar o Kafka a partir da linha de comando manualmente.

- Pode estar fazendo a montagem de um docker-compose.

- O Apache Kafka precisa do java para rodar ele ja vem dentro do container docker ent√£o nao precisa se preocupar

# **Como funciona dentro do container ?**

- E uma ferramenta multi-server e plataforma streaming que quer dizer os dados coletados em tempo real

[Video explicativo](https://www.youtube.com/watch?v=qOqXz5Qv_-8)

[Detalhes](https://medium.com/azure-na-pratica/apache-kafka-kafdrop-docker-compose-montando-rapidamente-um-ambiente-para-testes-606cc76aa66)

# **Quais sao suas depend√™ncias ?**

## **Zookeeper**

Zookeeper e Kafka trabalha de forma separada se comunicando entre si.

- Apache Zookeeper √© um servi√ßo centralizado para manter informa√ß√µes de configura√ß√µes e nomenclaturas entre servi√ßos distribu√≠dos. O Kafka utiliza o Zookeeper para sincronizar as configura√ß√µes entre diferentes clusters.

## **Kafka Connections**

**_Kafka Connect_** √© a estrutura de integra√ß√£o de dados declarativa e conect√°vel para Kafka. Ele conecta data sinks e fontes ao Kafka, deixando o resto do ecossistema fazer o que faz t√£o bem com t√≥picos cheios de eventos

O **_Kafka Connect_** pode criar um cluster de trabalhadores para tornar o processo de c√≥pia de dados escal√°vel e tolerante √† falhas. Os trabalhadores precisam armazenar algumas informa√ß√µes sobre seu status, seu progresso na leitura de dados do armazenamento externo e assim por diante. Para armazenar esses dados, eles usam o Kafka como armazenamento.

![Connections](../../Images/Kafka/Kafka%20conect.jpg)

[Video Auxiliar](https://www.youtube.com/watch?v=h44GZk2gkCI)

## **Java**

O Kafka precisa do java para poder ser usado, ent√£o √© obrigat√≥rio possuir a vers√£o atual do JDK na m√°quina.

## **Processamento em Kafka Python**

Para a utiliza√ß√£o dos recursos do Kafka, ser√° necess√°rio a utiliza√ß√£o do Python, mas √© importante saber que vamos presisar de dois scripts o `CONSUMER` eo `PRODUCER`.

[Video Pratico](https://www.youtube.com/watch?v=PppMhofKzy4)

# **Componentes ?**

Kafka tem uns componentes arquiteturais que detalharei a seguir e vai ficar f√°cil de entender: mensagem, offset, t√≥pico, partition, broker.

**_üí•ASSISTA OS VIDEOS ANTES DE COME√áAR A LER ESSA PARTEüí•_**

- [Componentes](https://atitudereflexiva.wordpress.com/2020/03/05/apache-kafka-introducao/)

- [Conceito de cada componente](https://imasters.com.br/software/apache-kafka-entenda-conceitos-arquiteturas-e-componentes)

- [Video Explicativo](https://www.youtube.com/watch?v=uu6F6yvCXzc)

- [Video da fullcycle](https://www.youtube.com/watch?v=ZztfRR2T-N0)

## **Mensagens (Dados)**

Basicamente, o Kafka trabalha com streaming de dados, com o conceito de T√≥picos, onde existe o Produtor e o Consumidor. O Produtor envia suas mensagens para o T√≥pico e elas ficam l√° guardadas at√© o Consumidor ler esse t√≥pico e peg√°-las.

- [Video Explicativo](https://www.youtube.com/watch?v=HHYfCkW_ABY)

## **Streaming (Fluxo de dados)**

O Apache Kafka √© incorporado a pipelines de transmiss√£o que compartilham dados entre sistemas e/ou aplica√ß√µes, bem como a sistemas e aplica√ß√µes que consomem esses dados. O Apache Kafka √© compat√≠vel com v√°rios casos de uso, em que alta produtividade e escalabilidade s√£o fatores vitais.

- [Video Explicativo](https://www.youtube.com/watch?v=HHYfCkW_ABY)

## **T√≥pico**

Um t√≥pico √© como categorizamos grupos de mensagens dentro do Kafka. Todas as mensagens enviadas para o Kafka permanecem em um t√≥pico. Como comentado sobre Event Sourcing, mensagens s√£o imut√°veis e ordenadas. Para manter a ordena√ß√£o em um ecossistema de Kafka, os t√≥picos possuem parti√ß√µes e fatores de replica√ß√£o.

![Topics](../../Images/Kafka/topico.png)

- [Explica√ß√£o detalhada](https://vepo.github.io/posts/anatomia-de-um-topico)

## **Producer**

O produtor Kafka √© conceitualmente muito mais simples que o consumidor, pois n√£o precisa de coordena√ß√£o de grupo. Um particionador produtor mapeia cada mensagem para uma parti√ß√£o de t√≥pico e o produtor envia uma solicita√ß√£o de produ√ß√£o para o l√≠der dessa parti√ß√£o.

## **Consumer**

Os consumidores Kafka normalmente fazem parte de um grupo de consumidores. Quando v√°rios consumidores est√£o inscritos em um t√≥pico e pertencem ao mesmo grupo de consumidores, cada consumidor no grupo receber√° mensagens de um subconjunto diferente das parti√ß√µes no t√≥pico.

- [Consumindo mensagens](https://www.ibm.com/docs/pt-br/integration-bus/10.0?topic=bus-consuming-messages-from-kafka-topics)

## **Broker**

O conceito de broker na plataforma do Kafka √© nada mais do que praticamente o pr√≥prio Kafka, ele √© quem gerencia os t√≥picos, define a forma de armazenamento das mensagens, logs.

- [Video Explicativo](https://www.youtube.com/watch?v=ZLrkv53jqPo)

## **Cluster**

Um cluster Kafka √© um sistema que consiste em v√°rios Brokers, Topics e Partitions para ambos. O objetivo principal √© distribuir cargas de trabalho igualmente entre r√©plicas e parti√ß√µes.

![](../../Images/Kafka/Multi-cluster-.gif)

## **Log file**

- Os logs do Apache Kafka s√£o uma cole√ß√£o de v√°rios segmentos de dados presentes em seu disco, tendo um nome como o de uma parti√ß√£o de t√≥pico de formul√°rio ou qualquer parti√ß√£o de t√≥pico espec√≠fica. Cada log do Kafka fornece uma representa√ß√£o l√≥gica de um particionamento baseado em t√≥pico exclusivo.

- O login no Apache Kafka traz muitos benef√≠cios, n√£o apenas fornece uma solu√ß√£o padr√£o do setor para anexar logs de dados, mas tamb√©m fornece uma solu√ß√£o altamente escal√°vel para armazenar logs de dados. Os logs do Apache Kafka fornecem suporte de integra√ß√£o robusto para v√°rios aplicativos pr√©-existentes, permitindo que os usu√°rios integrem seus aplicativos usando um passo de configura√ß√£o f√°cil de seguir.

![](../../Images/Kafka/logk.webp)

## **Particionamento**

- As partitions ou parti√ß√µes como o pr√≥prio nome disse √© a camada de parti√ß√£o das mensagens dentro de um t√≥pico, este particionamento garante a elasticidade, toler√¢ncia a falha e escalabilidade do Apache Kafka, portanto cada t√≥pico pode ter varias parti√ß√µes em diferentes localidades

- Toda parti√ß√£o de um t√≥pico no Kafka pode ser consumida por um ou mais consumidores, desde que estes estejam em grupos de consumidores separados. Devido ao fato do Kafka ser um sistema distribu√≠do, esses grupos de consumidores podem estar em brokers diferentes geograficamente distribu√≠dos

![](../../Images/Kafka/particoes-kafka.png)

[kafka com python](https://timber.io/blog/hello-world-in-kafka-using-python/)

[kafka instalasao](https://www.youtube.com/watch?v=7nMDJzao31c&t=715s)

## **R√©plicas**

Replica√ß√£o significa simplesmente manter c√≥pias dos dados no cluster para promover o recurso de disponibilidade em qualquer aplicativo. A replica√ß√£o no Kafka est√° no n√≠vel da parti√ß√£o. Cada parti√ß√£o tem 0 ou mais replica√ß√µes no cluster.

![replica](../../Images/Kafka/replica.webp)

- [Organiza√ß√£o dos dados](https://hevodata.com/learn/kafka-replication/)

## **Segmentos**

Os segmentos ficam dentro das parti√ß√µes e segmentam as informa√ß√µes contidas nos logs files daquela parti√ß√£o, todo t√≥pico possui sua parti√ß√£o e sua segmenta√ß√£o, a segmenta√ß√£o serve para gerenciar a ordena√ß√£o da informa√ß√£o do log file bem como o tempo que ela ira ficar persistida.

![Segmento](../../Images/Kafka/segmento.png)

# **Como usar ?**

- Em sua estrutura, o Kafka possui consumers e producers. Para definir esses termos, basta traduzir: os producers s√£o os produtores das mensagens (quem envia e distribui os dados). J√° os consumers s√£o os consumidores das mensagens (eles se inscrevem em um t√≥pico e ficam ouvindo as mensagem que chegar√£o

- √â poss√≠vel usar um n√≥ KafkaConsumer em um fluxo de mensagens para assinar um t√≥pico especificado em um servidor Kafka. Em seguida, o n√≥ KafkaConsumer recebe mensagens que s√£o publicadas no t√≥pico Kafka como entradas para o fluxo de mensagens.

- Voc√™ pode usar o n√≥ KafkaProducer para publicar mensagens que s√£o geradas de dentro do seu fluxo de mensagens para um t√≥pico hospedado em um servidor Kafka . As mensagens publicadas ficam, ent√£o, dispon√≠veis para serem recebidas pelos consumidores (assinantes) por meio da leitura do t√≥pico. Voc√™ pode usar um n√≥ KafkaConsumer em um fluxo de mensagens para se inscrever em um t√≥pico especificado em um servidor Kafka . Para obter mais informa√ß√µes sobre o uso do n√≥ KafkaConsumer , consulte Consumindo mensagens de Kafka t√≥picos.

# **Uso do Python ?**

Kafka usa um protocolo bin√°rio sobre TCP. O protocolo define todas as APIs como pares de mensagens de resposta de solicita√ß√£o que sao constru√≠das em python.

- [Integra√ß√£o](https://cicerojmm.medium.com/processamento-e-an%C3%A1lise-de-dados-em-tempo-real-com-kafka-e-python-952be439b0fb)
- [kafka python exemplo](https://selectfrom.dev/apache-spark-structured-streaming-via-docker-compose-3e1f146384b9)

# **Como se encaixa em todo o processo ?**

O Kafka √© o processo inicial de todo o fluxo de dados fazendo a extra√ß√£o das fontes de dados.

> **Onde vai para cada fluxo de dados da ferramenta ?**

O Fluxo de dados nessa ferramenta √© de acordo com o projeto ou dimens√£o que vai ser criada para os projetos de cada setor.

> **De qual processo ela faz parte ?**

Da parte inicial do processo fazendo a extra√ß√£o dos dados.

> **Como dar deploy da aplica√ß√£o ?**

- [confluent Aprendizado kafka](https://www.confluent.io/online-talks/online-training-fundamentals-for-apache-kafka-v1/?utm_medium=display&utm_source=google&utm_campaign=ch.display_tp.rmkt_tgt.key-page-visit-no-hva_rgn.latam_lng.eng_dv.all_con.kafka-fundamentals-3-part-webinar&utm_term=&creative=akfunseries3part-180Days&device=c&placement=www.youtube.com&gclid=Cj0KCQjwpeaYBhDXARIsAEzItbGuI_i-SiX0OJCM5tYeQ9Lal4EntiKFDBNu4He_7cFnYAohTJ2RfmoaApF5EALw_wcB)

- [Conecta a Rede](https://docs.microsoft.com/pt-br/azure/hdinsight/kafka/apache-kafka-connect-vpn-gateway)

- **MongoDB**

  - [Video](https://www.youtube.com/watch?v=_6NuTTQdDn4)

- **Spark**

  - [Integra√ß√£o](https://www.youtube.com/watch?v=zVgPNjSjua0&t=573s)
  - [Video](https://www.youtube.com/watch?v=2z6scTH_C4c)
  - [Modelo ideal](https://wiadrodanych.pl/big-data/predkosc-apache-spark-gps-komunikacji-miejskiej/)

- **Kubernetes**
  - [Deploy Kubernetes](https://levelup.gitconnected.com/how-to-deploy-apache-kafka-with-kubernetes-9bd5caf7694f)
